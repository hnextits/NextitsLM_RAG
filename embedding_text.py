#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import re
import json
import logging
from typing import List, Dict, Tuple, Any
from dataclasses import dataclass
from pathlib import Path
import numpy as np
import torch
import markdown
from bs4 import BeautifulSoup
import argparse  # <--- [ìˆ˜ì •] ì´ ì¤„ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!
from tqdm import tqdm
from datetime import datetime
import hashlib
import uuid

# ğŸ’¡ Sentence Transformersì™€ Weaviate í´ë¼ì´ì–¸íŠ¸ ì„í¬íŠ¸
from shared_embedding import shared_embedding
import weaviate
from weaviate.util import generate_uuid5
from weaviate.exceptions import UnexpectedStatusCodeException
from weaviate.classes.config import Configure, Property, DataType
from config import RAGConfig
from weaviate_utils import create_schema as create_utils_schema
from weaviate_utils import create_schema as ensure_all_schema

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =============================================================================
# ğŸ’¡ Weaviate ë° Config ì„¤ì •
# =============================================================================

class RAGConfig:
    """Weaviate ì—°ê²° ë° í´ë˜ìŠ¤ ì´ë¦„ ì„¤ì •"""
    def __init__(self):
        import os
        self.WEAVIATE_URL = os.getenv("WEAVIATE_URL", "http://localhost:8080")
        self.WEAVIATE_TEXT_CLASS = "TextDocument"
        # ğŸ’¡ ì°¸ê³ : ì´ íŒŒì¼ì—ì„œ WEAVIATE_DOCUMENT_CLASSëŠ” ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤.

    def get_weaviate_client(self):
        """Weaviate í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            # v4 API ì‚¬ìš©
            host = self.WEAVIATE_URL.replace('http://', '').replace('https://', '').split(':')[0]
            port = int(self.WEAVIATE_URL.split(':')[-1]) if ':' in self.WEAVIATE_URL.split('//')[-1] else 8080
            
            client = weaviate.connect_to_custom(
                http_host=host,
                http_port=port,
                http_secure=False,
                grpc_host=host,
                grpc_port=50051,
                grpc_secure=False
            )
            if client.is_ready():
                return client
            else:
                logger.error(f"Weaviate is not ready at {self.WEAVIATE_URL}")
                client.close()
                return None
        except Exception as e:
            logger.error(f"Weaviate í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

def create_schema(client):
    """í•„ìš”í•œ Weaviate ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (v4 API)"""
    
    config = RAGConfig()
    
    try:
        # v4 API: collectionì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if client.collections.exists(config.WEAVIATE_TEXT_CLASS):
            logger.info(f"Collection '{config.WEAVIATE_TEXT_CLASS}' already exists")
            return
        
        # v4 APIë¡œ collection ìƒì„±
        client.collections.create(
            name=config.WEAVIATE_TEXT_CLASS,
            description="Text chunks and their embeddings.",
            vectorizer_config=Configure.Vectorizer.none(),
            properties=[
                Property(name="text", data_type=DataType.TEXT),
                Property(name="title", data_type=DataType.TEXT),
                Property(name="source", data_type=DataType.TEXT),
                Property(name="page_num", data_type=DataType.INT),
                Property(name="chunk_id", data_type=DataType.TEXT),
                Property(name="document_uuid", data_type=DataType.TEXT),
                Property(name="metadata", data_type=DataType.OBJECT, nested_properties=[
                    Property(name="document_id", data_type=DataType.TEXT),
                    Property(name="content_type", data_type=DataType.TEXT),
                    Property(name="file_path", data_type=DataType.TEXT)
                ]),
            ]
        )
        logger.info(f"Created schema collection: {config.WEAVIATE_TEXT_CLASS}")
            
    except Exception as e:
        logger.error(f"Weaviate ìŠ¤í‚¤ë§ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
# -----------------------------------------------------------------------


# =============================================================================
# ë°ì´í„° êµ¬ì¡° ë° í”„ë¡œì„¸ì„œ í´ë˜ìŠ¤ (ì´ì „ê³¼ ë™ì¼)
# =============================================================================

@dataclass
class ChunkInfo:
    """ì²­í¬ ì •ë³´ êµ¬ì¡°ì²´"""
    chunk_id: str
    text: str
    raw_text: str
    start_pos: int
    end_pos: int
    token_start: int
    token_end: int
    chunk_index: int
    document_id: str
    content_type: str
    metadata: Dict[str, Any]

@dataclass
class VectorEntry:
    """ë²¡í„° ì €ì¥ ì—”íŠ¸ë¦¬"""
    id: str
    document_id: str
    chunk_id: str
    text: str
    raw_text: str
    embedding: np.ndarray
    content_type: str
    metadata: Dict[str, Any]
    created_at: datetime

class MixedContentProcessor:
    def __init__(self):
        self.md_parser = markdown.Markdown(extensions=['fenced_code', 'tables'])
        self.latex_patterns = {
            'inline_paren': re.compile(r'\\\((.*?)\\\)', re.DOTALL),
            'inline_dollar': re.compile(r'\$([^$]+)\$'),
            'display_bracket': re.compile(r'\\\[(.*?)\\]', re.DOTALL),
            'display_dollar': re.compile(r'\$\$(.*?)\$\$', re.DOTALL),
        }
        self.table_pattern = re.compile(r'<table.*?</table>', re.DOTALL | re.IGNORECASE)
        self.code_pattern = re.compile(r'```.*?```', re.DOTALL)

    def process_markdown(self, file_path: str) -> Dict[str, Any]:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        html = self.md_parser.convert(content)
        soup = BeautifulSoup(html, 'html.parser')
        sections = []
        for element in soup.find_all(['p', 'li', 'pre', 'blockquote', 'table']):
            text = element.get_text().strip()
            if not text:
                continue
            raw_text = str(element)
            content_type = self._identify_content_type(raw_text)
            sections.append({
                'text': text,
                'raw_text': raw_text,
                'content_type': content_type,
                'metadata': {}
            })
        return {'sections': sections, 'raw_content': content}

    def _identify_content_type(self, text: str) -> str:
        if any(pattern.search(text) for pattern in self.latex_patterns.values()):
            return 'latex'
        if self.table_pattern.search(text):
            return 'table'
        if self.code_pattern.search(text):
            return 'code'
        return 'text'

class EnhancedSemanticChunker:
    def __init__(self, max_chunk_size: int = 1000, overlap_size: int = 100):
        self.max_chunk_size = max_chunk_size
        self.overlap_size = overlap_size

    def chunk_by_content_type(self, processed_data: Dict[str, Any]) -> List[Dict]:
        sections = processed_data['sections']
        chunks = []
        current_chunk_text = ""
        current_chunk_raw = ""
        for section in sections:
            if len(current_chunk_text) + len(section['text']) > self.max_chunk_size:
                if current_chunk_text:
                    chunks.append({'text': current_chunk_text, 'raw_text': current_chunk_raw, 'content_type': 'mixed'})
                current_chunk_text = section['text']
                current_chunk_raw = section['raw_text']
            else:
                current_chunk_text += "\n\n" + section['text']
                current_chunk_raw += "\n\n" + section['raw_text']
        if current_chunk_text:
            chunks.append({'text': current_chunk_text, 'raw_text': current_chunk_raw, 'content_type': 'mixed'})
        return chunks

class WeaviateVectorStore:
    """Weaviate ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ (ë°°ì¹˜ ì €ì¥ ë¡œì§ í¬í•¨)"""
    def __init__(self):
        self.config = RAGConfig()
        self.client = None
        self._init_client()

    def _init_client(self):
        self.client = self.config.get_weaviate_client()
        if self.client:
            logger.info(f"Initialized Weaviate client: {self.config.WEAVIATE_URL}")
        else:
            logger.warning("Weaviate í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨. ë°ì´í„° ì €ì¥ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

    def add_vectors(self, vectors: List[VectorEntry]):
        if not vectors or not self.client:
            logger.warning("Weaviate í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        
        # 1. ë°°ì¹˜ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì²­í¬ ë°ì´í„° ì €ì¥ (v4)
        first_vec = vectors[0]
        metadata = first_vec.metadata
        file_path = metadata.get('file_path', '')
        filename = os.path.basename(file_path) if file_path else f"doc_{first_vec.document_id[:8]}"
        
        document_uuid = generate_uuid5(first_vec.document_id)

        document_metadata = {
            "document_id": first_vec.document_id,
        }
        if file_path:
            document_metadata["file_path"] = file_path
        content_type = getattr(first_vec, "content_type", None) or metadata.get("content_type")
        if content_type:
            document_metadata["content_type"] = content_type

        text_class_name = self.config.WEAVIATE_TEXT_CLASS
        collection = self.client.collections.get(text_class_name)
        
        # v4 API: batch context manager ì‚¬ìš©
        with collection.batch.dynamic() as batch:
            for vec in tqdm(vectors, desc="Adding chunks to Weaviate batch"):
                chunk_uuid = generate_uuid5(vec.chunk_id)
                chunk_metadata = {
                    "document_id": vec.document_id,
                }
                if vec.content_type:
                    chunk_metadata["content_type"] = vec.content_type

                properties = {
                    "text": vec.text,
                    "title": metadata.get('title', ''),
                    "source": file_path,
                    "page_num": metadata.get('page_num', 0),
                    "chunk_id": vec.chunk_id,
                    "document_uuid": str(document_uuid),
                    "metadata": {
                        **document_metadata,
                        **chunk_metadata,
                    },
                }
                
                batch.add_object(
                    properties=properties,
                    uuid=chunk_uuid,
                    vector=vec.embedding.tolist()
                )

        logger.info(
            "Successfully added %d chunk vectors to Weaviate for document %s (%s)",
            len(vectors),
            filename,
            document_uuid,
        )

# =============================================================================
# Qwen3LateChunker í´ë˜ìŠ¤
# =============================================================================

class Qwen3LateChunker:
    def __init__(self, chunk_size=1000, overlap_size=100):
        self.chunk_size = chunk_size
        self.overlap_size = overlap_size
        self.embedding_model = shared_embedding
        self.vector_store = WeaviateVectorStore()
        self.document_metadata = {}
    def process_markdown_file(self, file_path: str) -> str:
        start_time = datetime.now()
        document_id = self._generate_document_id(file_path)
        
        content_processor = MixedContentProcessor()
        processed_data = content_processor.process_markdown(file_path)
        
        chunker = EnhancedSemanticChunker(self.chunk_size, self.overlap_size)
        chunks = chunker.chunk_by_content_type(processed_data)
        
        chunk_infos = self._get_chunk_boundaries(file_path, processed_data['raw_content'], chunks, document_id)
        vector_entries = self._perform_late_chunking(chunk_infos)
        
        if vector_entries:
            self.vector_store.add_vectors(vector_entries)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        self.document_metadata[document_id] = {
            'filename': os.path.basename(file_path),
            'file_path': file_path,
            'processing_time': processing_time,
            'total_chunks': len(vector_entries),
            'created_at': datetime.now()
        }
        return document_id

    def _generate_document_id(self, file_path: str) -> str:
        return hashlib.md5(file_path.encode()).hexdigest()

    def _get_chunk_boundaries(self, file_path: str, full_text: str, chunks: List[Dict], document_id: str) -> List[ChunkInfo]:
        chunk_infos = []
        current_pos = 0
        
        for i, chunk in enumerate(chunks):
            chunk_text = chunk['text']
            chunk_start = full_text.find(chunk_text.strip(), current_pos)
            if chunk_start == -1:
                chunk_start = current_pos 
            
            chunk_end = chunk_start + len(chunk_text.strip())
            
            chunk_info = ChunkInfo(
                chunk_id=f"{document_id}_chunk_{i}", 
                text=chunk_text,
                raw_text=chunk.get('raw_text', chunk_text),
                start_pos=chunk_start,
                end_pos=chunk_end,
                token_start=0,
                token_end=0,
                chunk_index=i,
                document_id=document_id,
                content_type=chunk.get('content_type', 'text'),
                metadata={'file_path': file_path} 
            )
            chunk_infos.append(chunk_info)
            current_pos = chunk_end
        return chunk_infos

    def _perform_late_chunking(self, chunk_infos: List[ChunkInfo]) -> List[VectorEntry]:
        vector_entries = []
        if self.embedding_model._model is None:
                logger.error("Shared embedding model is not loaded.")
                return []

        for info in tqdm(chunk_infos, desc="Embedding chunks"):
            try:
                embedding = self.embedding_model.generate_embedding(info.text, normalize=True)
                
            except Exception as e:
                logger.error(f"Error generating embedding for chunk {info.chunk_id}: {str(e)}")
                if self.embedding_model.vector_dimension:
                        embedding = np.ones(self.embedding_model.vector_dimension) 
                else:
                    logger.error("Embedding dimension unknown, skipping chunk.")
                    continue

            entry = VectorEntry(
                id=info.chunk_id,
                document_id=info.document_id,
                chunk_id=info.chunk_id,
                text=info.text,
                raw_text=info.raw_text,
                embedding=embedding,
                content_type=info.content_type,
                metadata=info.metadata,
                created_at=datetime.now()
            )
            vector_entries.append(entry)
        return vector_entries

    def get_document_summary(self, document_id: str) -> Dict[str, Any]:
        if document_id in self.document_metadata:
            summary = self.document_metadata[document_id].copy()
            if 'created_at' in summary and isinstance(summary['created_at'], datetime):
                summary['created_at'] = summary['created_at'].isoformat()
            return summary
        return {"document_id": document_id, "status": "not_found"}

# =============================================================================
# ë²¡í„° ê²€ìƒ‰ í•¨ìˆ˜
# =============================================================================

def search_vectors(query: str, top_k: int = 5) -> List[Dict]:
    config = RAGConfig()
    client = config.get_weaviate_client()
    if not client:
        print("Weaviate í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    try:
        query_embedding = shared_embedding.generate_embedding(query)
        if query_embedding is None:
            raise ValueError("Query embedding generation failed.")
    except Exception as e:
        logger.error(f"Error generating query embedding: {e}")
        return []
    
    try:
        # v4 API: collectionì„ í†µí•œ ê²€ìƒ‰
        collection = client.collections.get(config.WEAVIATE_TEXT_CLASS)
        
        response = collection.query.near_vector(
            near_vector=query_embedding.tolist(),
            limit=top_k,
            return_metadata=['distance']
        )
        
        results = []
        for obj in response.objects:
            distance = obj.metadata.distance if obj.metadata.distance is not None else 1.0
            similarity_score = 1.0 - distance if 0.0 <= distance <= 1.0 else 0.0
            
            metadata = obj.properties.get("metadata", {})
            
            results.append({
                'score': similarity_score,
                'document_id': metadata.get('document_id', ''),
                'document_uuid': obj.properties.get('document_uuid', ''),
                'text': obj.properties.get('text', ''),
                'content_type': metadata.get('content_type', 'text'),
            })
        
        return results
    finally:
        client.close()

# =============================================================================
# Main í•¨ìˆ˜ (ìŠ¤í‚¤ë§ˆ ì‚­ì œ ë° ìƒì„± ìˆœì„œ ìˆ˜ì • ì™„ë£Œ)
# =============================================================================

def main(input_file=None, recreate_schema=False, search_mode=False):
    """
    Main function for chunking and indexing
    
    Args:
        input_file: Input markdown file path for processing
        recreate_schema: Whether to recreate Weaviate schema
        search_mode: Whether to enter interactive search mode
    """
    # ëª…ë ¹ì¤„ì—ì„œ ì‹¤í–‰ë  ë•Œë§Œ argparse ì‚¬ìš©
    if input_file is None and not recreate_schema and not search_mode:
        parser = argparse.ArgumentParser(description="Qwen3 Late Chunking and Weaviate Indexing")
        parser.add_argument('--input-file', type=str, help='Input markdown file path for processing.')
        parser.add_argument('--recreate-schema', action='store_true', help='Recreate Weaviate schema.')
        parser.add_argument('--search', action='store_true', help='Interactive search mode.')
        args = parser.parse_args()
        input_file = args.input_file
        recreate_schema = args.recreate_schema
        search_mode = args.search
    
    # ê°„ë‹¨í•œ ê°ì²´ë¡œ ë³€í™˜ (ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ì„± ìœ ì§€)
    class Args:
        pass
    args = Args()
    args.input_file = input_file
    args.recreate_schema = recreate_schema
    args.search = search_mode

    # [ìˆ˜ì •] config.pyì—ì„œ RAGConfigë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •
    try:
        logger.info("config.pyì—ì„œ RAGConfig ë¡œë“œ ì„±ê³µ.")
    except ImportError:
        logger.error("config.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. embedding_text.pyì˜ ë¡œì»¬ RAGConfigë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # config.pyê°€ ì—†ìœ¼ë©´ ì´ íŒŒì¼ì˜ ë¡œì»¬ RAGConfigë¥¼ ì‚¬ìš© (ê¸°ì¡´ ë°©ì‹)
        pass

    config = RAGConfig()
    client = config.get_weaviate_client()
    
    if args.recreate_schema:
        if client:
            logger.warning("Weaviate ìŠ¤í‚¤ë§ˆ ì¬ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤ (ëª¨ë“  ë°ì´í„° ì‚­ì œ).")
            
            # weaviate_utils.pyì— ì •ì˜ëœ (recreate=Trueë¥¼ ì§€ì›í•˜ëŠ”) 
            # create_schema í•¨ìˆ˜ë¥¼ ì„í¬íŠ¸í•˜ì—¬ ê°•ì œ ì¬ìƒì„±
            try:
                
                # recreate=Trueë¡œ í˜¸ì¶œí•˜ì—¬ delete_all() ì‹¤í–‰
                success = create_utils_schema(client, recreate=True) 
                
                if success:
                    logger.info("ìŠ¤í‚¤ë§ˆ ì¬ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    logger.error("ìŠ¤í‚¤ë§ˆ ì¬ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

            except ImportError:
                logger.error("weaviate_utils.pyë¥¼ ì„í¬íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚¤ë§ˆ ì¬ìƒì„± ì‹¤íŒ¨.")
            except Exception as e:
                logger.error(f"ìŠ¤í‚¤ë§ˆ ì¬ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            # ^^^^ [ìˆ˜ì •] ^^^^
        else:
            logger.error("Weaviate í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ì–´ ìŠ¤í‚¤ë§ˆë¥¼ ì¬ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return # ìŠ¤í‚¤ë§ˆ ì¬ìƒì„± í›„ ì¢…ë£Œ

    if args.search:
        while True:
            try:
                query = input("\nê²€ìƒ‰ ì¿¼ë¦¬: ")
                if query.lower() in ['exit', 'quit']:
                    break
                results = search_vectors(query)
                print(json.dumps(results, indent=2, ensure_ascii=False))
            except (KeyboardInterrupt, EOFError):
                break
        return

    if not args.input_file:
        parser.error("--input-file is required.")
        return

    try:
        if client:

            try:
                ensure_all_schema(client, recreate=False) # recreate=Falseë¡œ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸
            except ImportError:
                logger.warning("weaviate_utils.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¡œì»¬ create_schemaë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                # ì„í¬íŠ¸ ì‹¤íŒ¨ ì‹œ ë¡œì»¬ create_schema ì‚¬ìš© (ê¸°ì¡´ ë°©ì‹)
                if 'create_schema' in locals():
                    create_schema(client)

            logger.info(f"Weaviate client ready at {config.WEAVIATE_URL}")
        else:
            logger.warning("Weaviate client not ready. Indexing will fail.")
        
        chunker = Qwen3LateChunker() 
        document_id = chunker.process_markdown_file(args.input_file)
        summary = chunker.get_document_summary(document_id)
        print("\nDocument Summary:")
        print(json.dumps(summary, indent=2, ensure_ascii=False))
        logger.info(f"Indexing completed. Total chunks: {summary.get('total_chunks', 0)}")
    except Exception as e:
        logger.error(f"FATAL ERROR during chunker processing: {e}")

if __name__ == "__main__":
    main()